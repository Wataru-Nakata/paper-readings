[
  {
    "title": "Generative Annotation for ASR Named Entity Correction",
    "category": "ASR",
    "date": "2025-09-05",
    "link": "https://www.arxiv.org/abs/2508.20700",
    "note": "ASRの固有名詞誤認識を訂正する手法として、従来は (固有名詞, 音素列) のペアを用いた編集距離ベースの手法 (Phonetic-level Edit Distance: PED) が用いられてきた PEDベースの手法は認識結果が目標の固有名詞と大きく異なる場合、PEDも大きくなって編集が困難であった (例: midjourney→米德仲尼 のようなケース) 本研究では音声特徴量ベースの固有名詞検索とAttention Encoder-Decoderによる生成的な誤り訂正を組み合わせることで、誤認識結果が表記上遠い場合でも頑健な修正を実現 現状は検索にself-attentionを使っており固有名詞数が増えると遅延が問題になるため、将来的にvector search等に置換できるとよさそうとのこと\n"
  },
  {
    "title": "CLEAR: Continuous Latent Autoregressive Modeling for High-quality and Low-latency Speech Synthesis",
    "category": "TTS",
    "date": "2025-09-04",
    "link": "https://arxiv.org/abs/2508.19098",
    "note": "離散音声トークンを用いたAR型TTSは高品質だが長い系列を予測する必要があり、推論速度に課題がある 本研究では、wav-VAEで抽出される連続潜在空間における自己回帰モデルCLEARを提案し、系列長を削減することでこの問題に対処 連続潜在空間を得るためのwav-VAEは1秒間の16kHzの音声を7.8個x1024次元のベクトルに圧縮/復元するため、高い推論効率を実現 ARモデルはTransformerの後段に各トークンに対して独立に動作するRectified Flow Headを結合することで連続潜在空間の予測精度を向上 LibriHeavyを用いて学習し従来のAR型TTSと同等の品質を達成しつつRTFを改善、streamingでは遅延96msを達成\n"
  },
  {
    "title": "SpectroStream: A Versatile Neural Codec for General Audio",
    "category": "NAC",
    "date": "2025-09-03",
    "link": "https://arxiv.org/abs/2508.05207",
    "note": "汎用的な音の離散表現獲得のためのSoundStreamの後継NACとして、48kHzのステレオ波形を25Hz64コードブック（最大）で表現するSpectroStreamを提案 Encoder, Decoderは100Hzのメルスペクトログラムを入出力とした2D Convベースのstreaming可能な構造で、QuantizerはRVQを使用 同一のビットレートでDACよりも高いViSQOLおよび主観評価スコアを獲得しており、特に低ビットレート（~3kbps）での改善が顕著 https://huggingface.co/google/magenta-realtime で学習済みモデルが公開されている\n"
  },
  {
    "title": "FastVLM: Efficient Vision Encoding for Vision Language Models",
    "category": "Multimodal (T/I)",
    "date": "2025-09-03",
    "link": "https://arxiv.org/abs/2412.13303",
    "note": "FastViTを改良したFastViTHDとQwen2-0.5B/1.5B/7Bと組み合わせたVLMを提案 FastViTHDはダウンサンプリング層を追加しトークン数を1/4に削減しつつ、DWConvベースのプーリング層を追加することで高解像な特徴も保持 画像トークン数の削減により画像のエンコード、LLMのprefillにかかる時間を削減し、TTFTを大幅に短縮 デモではiPhone上でリアルタイムにVLMが動作する様子も見られる\n"
  },
  {
    "title": "OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation",
    "category": "Multimodal (T/S)",
    "date": "2025-09-02",
    "link": "https://arxiv.org/abs/2410.17799",
    "note": "Qwen2.5-0.5Bをfull-duplexな音声対話モデルに拡張したOmniFlattenを提案 学習は (1)約10万時間のASR/TTSで音声モダリティに適応 (2)SpeechGPTのようにhalf-duplex型学習 (3)ユーザー音声10トークンからシステムテキスト2トークンとシステム音声10トークンを生成するfull-duplex型学習 の3段階 実験ではカリキュラム学習の有効性、Moshiよりも高い応答品質を確認したが、ベースモデルと比較した場合の品質低下、システムテキストを介さない場合にはさらなる品質低下も見られた 平均応答時間はMoshiよりもさらに速い模様（システム側553ms→193ms、ユーザ側753ms→287ms） CosyVoiceの音声トークナイザーを用いているとあるがこれはnon-causalっぽいので、学習段階(1)(2)と(3)の不整合が問題にならないのか気になる\n"
  },
  {
    "title": "rStar2-Agent: Agentic Reasoning Technical Report",
    "category": "LLM",
    "date": "2025-09-02",
    "link": "https://arxiv.org/abs/2508.20722",
    "note": "外部ツール（Python）の呼び出しを含めたエージェント的な強化学習により、14Bパラメータのモデルで671BパラメータのDeepseek-R1を上回る数学能力を達成 従来数学やコーディング分野で用いられていた出力の正誤で報酬を与える方法では、誤ったツール呼び出しを抑制できなかった これに対し、初めにバッチサイズ以上の応答を生成し、(1)正答できた応答は最善の1サンプルを選択 (2)誤った応答はランダムに残りのバッチを埋めるよう選択するResample on Correct (RoC)を提案 強化学習は(1)8Kコンテキストでの簡潔な応答生成 (2)12Kコンテキストに拡張した応答生成 (3)難しい問題に絞っての学習 の3段階で実施し、計510ステップで完了\n"
  },
  {
    "title": "On the Theoretical Limitations of Embedding-Based Retrieval",
    "category": "Text Embedding",
    "date": "2025-09-01",
    "link": "https://arxiv.org/abs/2508.21038",
    "note": "テキスト埋め込みに基づく情報検索では、埋め込みの次元によって表現できる組み合わせの数が制限され、表現不可能な検索タスクが存在することを理論的に示した また上記の検証のために現実的で自由度が高い検索タスクからなるLIMITデータセットを提案し、最新の埋め込みを利用しても性能が上げられないことを確認した\n"
  },
  {
    "title": "TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling",
    "category": "NAC",
    "date": "2025-08-31",
    "link": "https://arxiv.org/abs/2508.16790",
    "note": "デコーダにテキスト情報を与えることで、6.25Hzと超低ビットレートながら高い音声再構成品質を実現 エンコーダ・デコーダともdiffusion transformerベースで、後段でメルスペクトログラム→波形への変換も必要なため、リアルタイム応用に課題があるかも\n"
  },
  {
    "title": "SimPO: Simple Preference Optimization with a Reference-Free Reward",
    "category": "LLM",
    "date": "2025-08-30",
    "link": "https://arxiv.org/abs/2405.14734",
    "note": "DPOは人間の嗜好を反映する強化学習手法として広く用いられているが、参照モデルと現在のモデルの両方で対数尤度を計算する必要があった SimPOは参照モデルを用いず、系列長による正規化と良い回答・悪い回答間のマージンを導入することでより効率的な学習を実現 Mistral, Llama 3, Gemma2を用いた実験ではDPO以上の性能を達成\n"
  },
  {
    "title": "Prompt-Guided Turn-Taking Prediction",
    "category": "Speech",
    "date": "2025-08-30",
    "link": "https://arxiv.org/abs/2506.21191",
    "note": "VAPモデルのSAの前後にテキストプロンプトの埋め込みを結合することで、「リズムよく返答する」「話し出す前にポーズを入れる」といったターンテイキングのテキスト制御を実現\n"
  },
  {
    "title": "Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM",
    "category": "Multimodal (T/S)",
    "date": "2025-08-30",
    "link": "https://arxiv.org/abs/2411.00774",
    "note": "LLMのパラメータを固定して音声エンコーダ・音声デコーダ・ターンテイキング推定モジュールを学習した音声対話モデルを提案 音声入力は (1)音声認識でエンコーダ学習 (2)Adapter/LLMを結合して音声認識で学習 (3)マルチターンQAで学習 の3段階 音声出力は (1)TiCodec (40Hz, 1024コード) 学習 (2)LLMのembeddingから音声トークンを予測するよう学習 (3)LLMの中間特徴量を考慮して音声トークンを予測するよう学習 の3段階 SpeechGPT, Spectron, Moshi, GLM-4-Voiceよりも高品質な応答を~1.2秒で生成可能\n"
  },
  {
    "title": "Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities",
    "category": "Multimodal (T/S)",
    "date": "2025-08-29",
    "link": "https://arxiv.org/abs/2503.04721",
    "note": "ポーズ、相槌、ターンテイキング、遮りといった双方向音声対話の特徴を捉えるためのデータセットおよび評価手法を提案 データセットはCandor (850時間, ポーズ・ターンテイキング評価用), ICC (28分, 相槌評価用), 合成データ (337サンプル, ポーズ・遮り評価用) から成る cascade型のFreeze-Omniはs2s型のdGSLM, Moshiと比較してユーザー発話の遮りが少なく応答も適切だが、ターンの切り替わりが遅く相槌も少なめと評価された\n"
  },
  {
    "title": "VoxDialogue: Can Spoken Dialogue Systems Understand Information Beyond Words?",
    "category": "Multimodal (T/S)",
    "date": "2025-08-29",
    "link": "https://openreview.net/forum?id=vbmSSIhKAM",
    "note": "音声対話モデルが文脈だけでなく、話速・音量・強調・背景音といった音声特有の側面を考慮できているかを評価するための、4,500件のマルチターン対話データを提案 ASRベースのシステム (FunAudioLLM) は文脈に沿った応答ができていた一方で、音声の特徴の把握が必要な対話ではASRフリーなシステム (Qwen2-Audio等) に軍配 WavRewardの前身となるような研究のよう（著者の所属も浙江大学で共通）\n"
  },
  {
    "title": "Predicting the Order of Upcoming Tokens Improves Language Modeling",
    "category": "LLM",
    "date": "2025-08-29",
    "link": "https://arxiv.org/abs/2508.19228",
    "note": "未来のトークンを複数予測するMulti-Token Prediction (MTP)は難しすぎるという仮説から、各トークンが次に出現するまでの距離に基づくランクを予測するToken Order Prediction (TOP)を提案 340M~7Bのモデルを用いた実験では、MTPは評価指標によっては性能劣化につながることがあったが、TOPは一貫して改善が見られた\n"
  },
  {
    "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators",
    "category": "Multimodal (T/S)",
    "date": "2025-08-28",
    "link": "https://arxiv.org/abs/2505.09558",
    "note": "音声対話モデルを強化学習するためのデータセットChatReward-30Kと、それを用いてQwen2.5-Omni-7B-Thinkを強化学習した報酬モデルWavRewardを提案 データセットは応答の適切さだけでなく、話し方、話者性、感情等の音声特有の側面も考慮して1, 3, 5の3段階でスコアリング 音声対話のスコアリングにおいてGPT-4o-audioを超える性能を達成\n"
  },
  {
    "title": "LIST: Language-Independent Speech Token for Multilingual Speech Synthesis with Language Models",
    "category": "TTS",
    "date": "2025-08-28",
    "link": "https://www.isca-archive.org/interspeech_2025/liu25o_interspeech.pdf",
    "note": "ASRで学習される音声トークナイザーに対し、ASRのターゲットをIPAにすることで言語非依存な音声トークンを獲得する手法を提案 音声トークンからメルスペクトログラムを生成するflow matching部分は声質変換された音声から抽出された音声トークンを入力として学習することで話者非依存な音声トークンを獲得 TTSによる評価では、ASRのターゲットがテキスト（BPE）の場合と比較して、英語以外の全言語のCERを改善\n"
  },
  {
    "title": "OpusLM: A Family of Open Unified Speech Language Models",
    "category": "Multimodal (T/S)",
    "date": "2025-08-28",
    "link": "https://arxiv.org/abs/2506.17611",
    "note": "モデル、学習・推論コード、データを全て公開した1.3B/7Bの音声言語モデルを公開 モデルはsemantic token x 1, acoustic token x 8を一度に予測するマルチストリームな構造 ASR, TTS, NLPで高い性能を示すが、135Mや360Mでは大幅な性能劣化が見られ、モデルサイズの重要性を示唆\n"
  },
  {
    "title": "Scalable Spontaneous Speech Dataset (SSSD): Crowdsourcing Data Collection to Promote Dialogue Research",
    "category": "Dataset (Speech)",
    "date": "2025-08-27",
    "link": "https://www.isca-archive.org/interspeech_2025/sheikh25_interspeech.pdf",
    "note": "クラウドソーシングで2話者の自発的対話を収集した700時間超のデータセットを公開"
  },
  {
    "title": "Is Synthetic Data Truly Effective for Training Speech Language Models?",
    "category": "Multimodal (T/S)",
    "date": "2025-08-20",
    "link": "https://www.isca-archive.org/interspeech_2025/mizumoto25_interspeech.pdf"
  },
  {
    "title": "AC/DC: LLM-based Audio Comprehension via Dialogue Continuation",
    "category": "Multimodal (T/S)",
    "date": "2025-08-19",
    "link": "https://www.isca-archive.org/interspeech_2025/fujita25b_interspeech.pdf"
  },
  {
    "title": "Group Sequence Policy Optimization",
    "category": "LLM",
    "date": "2025-07-31",
    "link": "https://arxiv.org/abs/2507.18071"
  },
  {
    "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
    "category": "Multimodal (T/S/I/V)",
    "date": "2025-07-30",
    "link": "https://arxiv.org/abs/2507.06261"
  },
  {
    "title": "Towards a Japanese Full-duplex Spoken Dialogue System",
    "category": "Multimodal (T/S)",
    "date": "2025-06-30",
    "link": "https://arxiv.org/abs/2506.02979"
  },
  {
    "title": "OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary",
    "category": "ASR",
    "date": "2025-06-15",
    "link": "https://arxiv.org/abs/2506.09448"
  },
  {
    "title": "HiFiTTS-2: A Large-Scale High Bandwidth Speech Dataset",
    "category": "Dataset (Speech)",
    "date": "2025-06-05",
    "link": "https://arxiv.org/abs/2506.04152"
  },
  {
    "title": "CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training",
    "category": "TTS",
    "date": "2025-05-28",
    "link": "https://arxiv.org/abs/2505.17589"
  },
  {
    "title": "Understanding R1-Zero-Like Training: A Critical Perspective",
    "category": "LLM",
    "date": "2025-05-27",
    "link": "https://arxiv.org/abs/2503.20783"
  },
  {
    "title": "How Do Large Language Models Acquire Factual Knowledge During Pretraining?",
    "category": "LLM",
    "date": "2025-05-16",
    "link": "https://arxiv.org/abs/2406.11813"
  },
  {
    "title": "GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot",
    "category": "Multimodal (T/S)",
    "date": "2025-05-15",
    "link": "https://arxiv.org/abs/2412.02612"
  },
  {
    "title": "Qwen3: Think Deeper, Act Faster",
    "category": "LLM",
    "date": "2025-04-30",
    "link": "https://qwenlm.github.io/blog/qwen3/"
  },
  {
    "title": "ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning",
    "category": "LLM",
    "date": "2025-04-28",
    "link": "https://arxiv.org/abs/2412.03104"
  },
  {
    "title": "Context-aware Dynamic Pruning for Speech Foundation Models",
    "category": "Speech",
    "tags": [
      "ASR",
      "TTS"
    ],
    "date": "2025-04-23",
    "link": "https://openreview.net/forum?id=u2QdCiOgwA"
  },
  {
    "title": "An Evolved Universal Transformer Memory",
    "category": "LLM",
    "date": "2025-04-22",
    "link": "https://arxiv.org/abs/2410.13166"
  },
  {
    "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration",
    "category": "LLM",
    "date": "2025-04-18",
    "link": "https://arxiv.org/abs/2306.00978"
  },
  {
    "title": "ALMTokenizer: A Low-bitrate and Semantic-rich Audio Codec Tokenizer for Audio Language Modeling",
    "category": "NAC",
    "date": "2025-04-16",
    "link": "https://arxiv.org/abs/2504.10344"
  },
  {
    "title": "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space",
    "category": "LLM",
    "date": "2025-04-15",
    "link": "https://arxiv.org/abs/2402.12865"
  },
  {
    "title": "A Streamable Neural Audio Codec with Residual Scalar-Vector Quantization for Real-Time Communication",
    "category": "NAC",
    "date": "2025-04-14",
    "link": "https://arxiv.org/abs/2504.06561"
  },
  {
    "title": "Understanding R1-Zero-Like Training: A Critical Perspective",
    "category": "LLM",
    "date": "2025-04-11",
    "link": "https://arxiv.org/abs/2503.20783"
  },
  {
    "title": "VocalNet: Speech LLM with Multi-Token Prediction for Faster and High-Quality Generation",
    "category": "Multimodal (T/S)",
    "tags": [
      "LLM",
      "TTS"
    ],
    "date": "2025-04-10",
    "link": "https://arxiv.org/abs/2504.04060"
  },
  {
    "title": "The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation",
    "category": "LLM",
    "date": "2025-04-07",
    "link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/"
  },
  {
    "title": "MegaTTS 3: Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis",
    "category": "TTS",
    "date": "2025-04-03",
    "link": "https://arxiv.org/abs/2502.18924"
  },
  {
    "title": "MoCha: Towards Movie-Grade Talking Character Synthesis",
    "category": "THG",
    "date": "2025-04-01",
    "link": "https://arxiv.org/abs/2503.23307"
  },
  {
    "title": "Scaling Transformers for Low-Bitrate High-Quality Speech Coding",
    "category": "TTS",
    "date": "2025-03-31",
    "link": "https://arxiv.org/abs/2411.19842"
  },
  {
    "title": "Qwen2.5-Omni Technical Report",
    "category": "Multimodal (T/S/I/V)",
    "date": "2025-03-27",
    "link": "https://github.com/QwenLM/Qwen2.5-Omni/blob/main/assets/Qwen2.5_Omni.pdf"
  },
  {
    "title": "STFTCodec: High-Fidelity Audio Compression through Time-Frequency Domain Representation",
    "category": "NAC",
    "date": "2025-03-26",
    "link": "https://arxiv.org/abs/2503.16989"
  },
  {
    "title": "Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis",
    "category": "TTS",
    "date": "2025-03-25",
    "link": "https://arxiv.org/abs/2502.04128"
  },
  {
    "title": "SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound",
    "category": "NAC",
    "date": "2025-03-24",
    "link": "https://arxiv.org/abs/2502.04128"
  },
  {
    "title": "Gemma 3 Technical Report",
    "category": "LLM",
    "date": "2025-03-14",
    "link": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
  },
  {
    "title": "UniMax: Fairer and more Effective Language Sampling for Large-Scale Multilingual Pretraining",
    "category": "LLM",
    "date": "2025-03-13",
    "link": "https://arxiv.org/abs/2304.09151"
  },
  {
    "title": "ESPnet-SDS: Unified Toolkit and Demo for Spoken Dialogue Systems",
    "category": "Multimodal (T/S)",
    "date": "2025-03-12",
    "link": "https://arxiv.org/abs/2503.08533"
  },
  {
    "title": "FlowDec: A flow-based full-band general audio codec with high perceptual quality",
    "category": "NAC",
    "date": "2025-03-11",
    "link": "https://arxiv.org/abs/2503.01485"
  },
  {
    "title": "Good practices for evaluation of synthesized speech",
    "category": "TTS",
    "date": "2025-03-10",
    "link": "https://arxiv.org/abs/2503.03250"
  },
  {
    "title": "Talking Turns: Benchmarking Audio Foundation Models on Turn-Taking Dynamics",
    "category": "Multimodal (T/S)",
    "date": "2025-03-06",
    "link": "https://arxiv.org/abs/2503.01174"
  },
  {
    "title": "Chain of Draft: Thinking Faster by Writing Less",
    "category": "LLM",
    "date": "2025-03-04",
    "link": "https://arxiv.org/abs/2501.15907"
  },
  {
    "title": "ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation",
    "category": "TTI",
    "date": "2025-02-27",
    "link": "https://arxiv.org/abs/2502.18364"
  },
  {
    "title": "Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision",
    "category": "ML",
    "date": "2025-02-26",
    "link": "https://arxiv.org/abs/2109.08203"
  },
  {
    "title": "KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation",
    "category": "ML",
    "date": "2025-02-25",
    "link": "https://arxiv.org/abs/2406.05298"
  },
  {
    "title": "Spectral Codecs: Spectrogram-Based Audio Codecs for High Quality Speech Synthesis",
    "category": "NAC",
    "date": "2025-02-20",
    "link": "https://arxiv.org/abs/2406.05298"
  },
  {
    "title": "Emo-DPO: Controllable Emotional Speech Synthesis through Direct Preference Optimization",
    "category": "TTS",
    "date": "2025-02-19",
    "link": "https://arxiv.org/abs/2409.10157"
  },
  {
    "title": "SpeechAlign: Aligning Speech Generation to Human Preferences",
    "category": "TTS",
    "date": "2025-02-18",
    "link": "https://arxiv.org/abs/2404.05600"
  },
  {
    "title": "Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference",
    "category": "NAC",
    "date": "2025-02-17",
    "link": "https://arxiv.org/abs/2410.21951"
  },
  {
    "title": "Fast and High-Quality Auto-Regressive Speech Synthesis via Speculative Decoding",
    "category": "TTS",
    "date": "2025-02-13",
    "link": "https://arxiv.org/abs/2410.21951"
  },
  {
    "title": "Meta Audiobox Aesthetics: Unified Automatic Quality Assessment for Speech, Music, and Sound",
    "category": "Audio",
    "date": "2025-02-12",
    "link": "https://arxiv.org/abs/2502.05139"
  },
  {
    "title": "s1: Simple test-time scaling",
    "category": "LLM",
    "date": "2025-02-10",
    "link": "https://arxiv.org/abs/2501.19393"
  },
  {
    "title": "High-Fidelity Simultaneous Speech-To-Speech Translation",
    "category": "ST",
    "date": "2025-02-07",
    "link": "https://arxiv.org/abs/2502.03382"
  },
  {
    "title": "Wavelet-based Positional Representation for Long Context",
    "category": "LLM",
    "date": "2025-02-06",
    "link": "https://arxiv.org/abs/2502.02004"
  },
  {
    "title": "Investigating the Impact of Incremental Processing and Voice Activity Projection on Spoken Dialogue Systems",
    "category": "Multimodal (T/S)",
    "date": "2025-02-05",
    "link": "https://aclanthology.org/2025.coling-main.249/"
  },
  {
    "title": "BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data",
    "category": "TTS",
    "date": "2025-02-04",
    "link": "https://arxiv.org/abs/2402.08093"
  },
  {
    "title": "Finite Scalar Quantization: VQ-VAE Made Simple",
    "category": "ML",
    "date": "2025-02-03",
    "link": "https://arxiv.org/abs/2309.15505"
  },
  {
    "title": "Sigmoid Loss for Language Image Pre-Training",
    "category": "Multimodal (T/I)",
    "date": "2025-01-31",
    "link": "https://arxiv.org/abs/2303.15343"
  },
  {
    "title": "TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models",
    "category": "LLM",
    "date": "2025-01-30",
    "link": "https://arxiv.org/abs/2501.16937"
  },
  {
    "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
    "category": "LLM",
    "date": "2025-01-29",
    "link": "https://arxiv.org/abs/2501.12948"
  },
  {
    "title": "Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling",
    "category": "Multimodal (T/I)",
    "date": "2025-01-28",
    "link": "https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf"
  },
  {
    "title": "CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models",
    "category": "TTS",
    "date": "2025-01-27",
    "link": "https://arxiv.org/abs/2412.10117"
  },
  {
    "title": "MinMo: A Multimodal Large Language Model for Seamless Voice Interaction",
    "category": "LLM",
    "date": "2025-01-23",
    "link": "https://arxiv.org/abs/2501.06282"
  },
  {
    "title": "YaRN: Efficient Context Window Extension of Large Language Models",
    "category": "LLM",
    "date": "2025-01-22",
    "link": "https://arxiv.org/abs/2309.00071"
  },
  {
    "title": "DeepSeek-V3 Technical Report",
    "category": "LLM",
    "date": "2025-01-10",
    "link": "https://arxiv.org/abs/2412.19437"
  },
  {
    "title": "Phi-4 Technical Report",
    "category": "LLM",
    "date": "2025-01-09",
    "link": "https://arxiv.org/abs/2412.08905"
  },
  {
    "title": "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching",
    "category": "TTS",
    "date": "2025-01-08",
    "link": "https://arxiv.org/abs/2410.06885"
  },
  {
    "title": "StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models",
    "category": "TTS",
    "date": "2025-01-07",
    "link": "https://arxiv.org/abs/2306.07691"
  },
  {
    "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models",
    "category": "LLM",
    "date": "2025-01-06",
    "link": "https://arxiv.org/abs/2402.03300"
  },
  {
    "title": "Flow Matching for Generative Modeling",
    "category": "ML",
    "date": "2024-12-28",
    "link": "https://arxiv.org/abs/2210.02747"
  },
  {
    "title": "Matcha-TTS: A fast TTS architecture with conditional flow matching",
    "category": "TTS",
    "date": "2024-12-27",
    "link": "https://arxiv.org/abs/2309.03199"
  },
  {
    "title": "GLOBE: A High-quality English Corpus with Global Accents for Zero-shot Speaker Adaptive Text-to-Speech",
    "category": "Dataset (Speech)",
    "date": "2024-12-26",
    "link": "https://arxiv.org/abs/2406.14875"
  },
  {
    "title": "SONAR: Sentence-Level Multimodal and Language-Agnostic Representations",
    "category": "Multimodal (T/S)",
    "date": "2024-12-25",
    "link": "https://arxiv.org/abs/2308.11466"
  },
  {
    "title": "Large Concept Models: Language Modeling in a Sentence Representation Space",
    "category": "LLM",
    "date": "2024-12-24",
    "link": "https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/?utm_source=twitter&utm_medium=organic_social&utm_content=thread&utm_campaign=fair"
  },
  {
    "title": "SQ-Whisper: Speaker-Querying based Whisper Model for Target-Speaker ASR",
    "category": "ASR",
    "date": "2024-12-10",
    "link": "https://arxiv.org/abs/2412.05589"
  },
  {
    "title": "Towards Robust Speech Representation Learning for Thousands of Languages",
    "category": "Speech",
    "date": "2024-11-14",
    "link": "https://aclanthology.org/2024.emnlp-main.570/"
  },
  {
    "title": "BigCodec: Pushing the Limits of Low-Bitrate Neural Speech Codec",
    "category": "NAC",
    "date": "2024-11-13",
    "link": "https://arxiv.org/abs/2409.05377"
  },
  {
    "title": "Language Modeling Is Compression",
    "category": "LLM",
    "date": "2024-11-08",
    "link": "https://arxiv.org/abs/2309.10668"
  },
  {
    "title": "A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion",
    "category": "VC",
    "date": "2024-11-07",
    "link": "https://arxiv.org/abs/2111.02392"
  },
  {
    "title": "Knowledge Distillation from Self-Supervised Representation Learning Model with Discrete Speech Units for Any-to-Any Streaming Voice Conversion",
    "category": "VC",
    "date": "2024-11-06",
    "link": "https://www.isca-archive.org/interspeech_2024/kanagawa24b_interspeech.pdf"
  },
  {
    "title": "The Impact of Positional Encoding on Length Generalization in Transformers",
    "category": "LLM",
    "date": "2024-11-05",
    "link": "https://arxiv.org/abs/2305.19466"
  },
  {
    "title": "Very Attentive Tacotron: Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech",
    "category": "TTS",
    "date": "2024-11-01",
    "link": "https://arxiv.org/abs/2410.22179"
  },
  {
    "title": "Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities",
    "category": "Multimodal (T/S/I)",
    "date": "2024-10-18",
    "link": "https://arxiv.org/abs/2410.11190"
  },
  {
    "title": "HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis",
    "category": "TTS",
    "date": "2024-10-12",
    "link": "https://arxiv.org/abs/2410.04380"
  },
  {
    "title": "J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling",
    "category": "Dataset (Speech)",
    "date": "2024-10-11",
    "link": "https://arxiv.org/abs/2407.15828"
  },
  {
    "title": "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents",
    "category": "LLM",
    "date": "2024-10-10",
    "link": "https://arxiv.org/abs/2409.15594"
  },
  {
    "title": "Moshi: a speech-text foundation model for real-time dialogue",
    "category": "Multimodal (T/S)",
    "date": "2024-09-20",
    "link": "https://arxiv.org/abs/2410.00037"
  },
  {
    "title": "Super Monotonic Alignment Search",
    "category": "TTS",
    "date": "2024-09-17",
    "link": "https://arxiv.org/abs/2409.07704"
  },
  {
    "title": "LLaMA-Omni: Seamless Speech Interaction with Large Language Models",
    "category": "Multimodal (T/S)",
    "date": "2024-09-16",
    "link": "https://arxiv.org/abs/2409.06666"
  },
  {
    "title": "FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications",
    "category": "TTS",
    "date": "2024-09-11",
    "link": "https://arxiv.org/abs/2409.03283"
  },
  {
    "title": "Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming",
    "category": "Multimodal (T/S)",
    "date": "2024-09-10",
    "link": "https://arxiv.org/abs/2408.16725"
  },
  {
    "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling",
    "category": "NAC",
    "date": "2024-09-09",
    "link": "https://arxiv.org/abs/2408.16532"
  }
]
